{"cells":[{"cell_type":"markdown","metadata":{"id":"SBUQlueWTtE3"},"source":["Importing necessary files and Initialization from Assignment 4\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19257,"status":"ok","timestamp":1713732766140,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"VAanywByTtE4","outputId":"8120dd70-a26d-406e-a548-d3e03330463a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n","Requirement already satisfied: wiki_dump_reader in /usr/local/lib/python3.10/dist-packages (0.0.4)\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# %% [markdown]\n","# Importing Local File Paths\n","\n","# %%\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","\n","corpus_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/HindiCorpus.txt\"\n","preprocessed_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/ProcessedCorpus.txt\"\n","xml_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/hiwiki-latest-pages-articles.xml\"\n","stop_words_file=\"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/stopwords.txt\"\n","\n","corpus_limit=232729\n","preprocess_limit=4232433\n","gramms_limit=38735257\n","\n","# %% [markdown]\n","# Importing necessary libraries\n","\n","# %%\n","import multiprocessing\n","import time\n","\n","\n","from collections import Counter, defaultdict\n","!pip install wiki_dump_reader\n","from wiki_dump_reader import Cleaner, iterate\n","\n","import string\n","\n","from nltk import ngrams, word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","import numpy as np\n","from tqdm import tqdm\n","import math\n"]},{"cell_type":"markdown","metadata":{"id":"dwwH-b0YTtE5"},"source":["Common Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":31753,"status":"ok","timestamp":1713732797887,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"IlQO1CaMTtE6"},"outputs":[],"source":["# %% [markdown]\n","# Functions for generating number of tokens and vocabulary\n","\n","# %%\n","def gen_vocabulary(file):\n","\tword_list = []\n","\twith open(file, 'r', encoding=\"utf-8\") as f:\n","\t\tfor line in f:\n","\t\t\tword_list += (line.split(' '))\n","\n","\tword_counts = Counter(word_list)\n","\treturn word_counts\n","\n","# %% [markdown]\n","# Displaying Token Count and Vocabulary Count\n","\n","# %%\n","\n","vocab_counts = gen_vocabulary(preprocessed_file)\n","\n","# %% [markdown]\n","# Reducing the vocabulary to words which occur more than 100 times since the total vocabulary count cannot be allocated as a 2D matrix\n","\n","# %%\n","\n","vocab = {x for x, count in vocab_counts.items() if count >= 100}\n","\n","# %% [markdown]\n","# Necessary variables for making the Co-Occurance matrix\n","\n","# %%\n","vocab_list = list(vocab)\n","vocab_pos = {vocab_list[i]: i for i in range(len(vocab_list))}\n","vocab_idx = vocab_pos.copy()\n","vocab_idx.update({i: w for i, w in enumerate(vocab_list)})\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HiHehpJ2TtE6"},"source":["Sequential Processing - Co Occurance Matrix"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636891,"status":"ok","timestamp":1713732282162,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"IPjTGHEATtE7","outputId":"962e2ce7-eb75-43ac-dda7-9b7af441c7e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 38700000/38735257 [03:04<00:00, 209991.78it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Grams processed = 38735256\n","\n","\n","Elapsed time: 185.52026572000068 seconds\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def co_occurances(file):\n","\twindow = 5\n","\n","\t# Using a ramp of window 4\n","\tramp = [0] + [*range(window, 0, -1)]\n","\n","\toccurances = np.zeros((len(vocab), len(vocab)), dtype=np.int64)\n","\n","\tgram_count=0\n","\tline=''\n","\n","\twith open(file, 'r', encoding=\"utf-8\") as corpus:\n","\t\tfor corp in corpus:\n","\t\t\tline=corp\n","\n","\tpg_bar=tqdm(total=gramms_limit)\n","\n","\tall_grams = ngrams(word_tokenize(line), window+1,pad_right=True, pad_left=True)\n","\n","\tfor grams in all_grams:\n","\n","\t\tif grams[0] in vocab:\n","\t\t\tfor idx, gram in enumerate(grams):\n","\t\t\t\tif gram in vocab:\n","\t\t\t\t\toccurances[vocab_idx[grams[0]]][vocab_idx[gram]] += ramp[idx]\n","\n","\t\t# Doing the same as above with the gram reversed\n","\t\tgrams_rev = grams[::-1]\n","\n","\t\tif grams_rev[0] in vocab:\n","\t\t\tfor idx, gram in enumerate(grams_rev):\n","\t\t\t\tif gram in vocab:\n","\t\t\t\t\toccurances[vocab_idx[grams_rev[0]]][vocab_idx[gram]] += ramp[idx]\n","\n","\t\tgram_count+=1\n","\n","\t\tif gram_count % 100000 == 0:\n","\t\t\tpg_bar.update(100000)\n","\n","\tpg_bar.close()\n","\n","\tprint(f'\\nGrams processed = {gram_count}')\n","\n","\treturn occurances\n","\n","\n","start_time = time.perf_counter()\n","\n","cocrmat = co_occurances(preprocessed_file)\n","\n","end_time = time.perf_counter()\n","\n","elapsed_time = end_time - start_time\n","\n","print(\"\\n\\nElapsed time:\", elapsed_time, \"seconds\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TWYw0cjwTtE7"},"source":["Parallel Processing - Co Occurance Matrix"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3iQiBGlQTtE7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 17/17 [00:01<00:00, 13.03it/s]\n","100%|██████████| 17/17 [17:37<00:00, 62.18s/it]   \n"]},{"name":"stdout","output_type":"stream","text":["\n","Grams processed = 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 349914436/349914436 [03:15<00:00, 1792867.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Elapsed time: 1321.775573731 seconds\n"]}],"source":["def parse_grams(ramp,gramss,occurances):\n","\n","\tfor grams in gramss:\n","\t\t\tif grams[0] in vocab:\n","\t\t\t\tfor idx, gram in enumerate(grams):\n","\t\t\t\t\tif gram in vocab:\n","\t\t\t\t\t\toccurances[vocab_idx[grams[0]]*len(vocab)+vocab_idx[gram]] += ramp[idx]\n","\n","\t\t\t# Doing the same as above with the gram reversed\n","\t\t\tgrams_rev = grams[::-1]\n","\n","\t\t\tif grams_rev[0] in vocab:\n","\t\t\t\tfor idx, gram in enumerate(grams_rev):\n","\t\t\t\t\tif gram in vocab:\n","\t\t\t\t\t\toccurances[vocab_idx[grams_rev[0]]*len(vocab)+vocab_idx[gram]] += ramp[idx]\n","\n","\n","\n","def parallel_co_occurances(file):\n","\twindow = 5\n","\n","\t# Using a ramp of window 4\n","\tramp = [0] + [*range(window, 0, -1)]\n","\n","\toccurances=multiprocessing.Array('i', (len(vocab)* len(vocab)))\n","\n","\tgram_count=0\n","\tline=''\n","\n","\twith open(file, 'r', encoding=\"utf-8\") as corpus:\n","\t\tfor corp in corpus:\n","\t\t\tline=corp\n","\n","\n","\n","\tall_grams = ngrams(word_tokenize(line), window+1,pad_right=True, pad_left=True)\n","\tnum_processes = multiprocessing.cpu_count()\n","\tprocess_count=(gramms_limit-1)//num_processes\n","\tgram_parallel=[[] for _ in range(num_processes+1)]\n","\n","\tfor grams in all_grams:\n","\t\tgram_count+=1\n","\t\tgram_parallel[gram_count//process_count].append(grams)\n","\n","\tgram_count=0\n","\n","\tp=[]\n","\n","\tfor i in range(len(gram_parallel)):\n","\t\tp.append(multiprocessing.Process(target=parse_grams, args=(ramp,gram_parallel[i],occurances,)))\n","\n","\tfor i in tqdm(range(len(p))):\n","\t\tp[i].start()\n","\n","\tfor i in tqdm(range(len(p))):\n","\t\tp[i].join()\n","\n","\n","\n","\tprint(f'\\nGrams processed = {gram_count}')\n","\n","\tmat=np.zeros((len(vocab), len(vocab)), dtype=np.int64)\n","\n","\tfor i in tqdm(range(len(vocab)*len(vocab))):\n","\t\tmat[i%len(vocab)][i//len(vocab)]=occurances[i]\n","\n","\treturn mat\n","\n","\n","start_time = time.perf_counter()\n","\n","cocrmat_p = parallel_co_occurances(preprocessed_file)\n","\n","end_time = time.perf_counter()\n","\n","elapsed_time = end_time - start_time\n","\n","print(\"\\n\\nElapsed time:\", elapsed_time, \"seconds\")\n"]},{"cell_type":"markdown","metadata":{"id":"jtFueyDkUDSx"},"source":["Checking Relation between Co-Occurance matrix generated from Sequential and Parallel operation."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nwcTKr-9UM2s"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18706/18706 [02:04<00:00, 150.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Average Difference -  0.00019986314597206272\n","Maximum Difference -  6400\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["avg=0\n","max_diff=0\n","\n","for i in tqdm(range(len(vocab))):\n","    for j in range(len(vocab)):\n","        diff=abs(cocrmat[i][j]-cocrmat_p[i][j])\n","        if (diff>max_diff):\n","            max_diff=diff\n","        avg+=diff\n","\n","avg /= (len(vocab)*len(vocab))\n","\n","print (\"Average Difference - \",avg)\n","print(\"Maximum Difference - \",max_diff)"]},{"cell_type":"markdown","metadata":{"id":"PVZfsZEWTtE8"},"source":["Common Functions"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"p98PMY5rTtE9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18706/18706 [01:55<00:00, 162.53it/s]\n"]}],"source":["# %% [markdown]\n","# Calculating overall Pi and Pj values of the Co-Occurance matrix\n","\n","# %%\n","\n","def calculate_probability(co_occurrence_matrix):\n","\t# Calculate row sums and column sums\n","\trow_sums = np.sum(co_occurrence_matrix, axis=1)\n","\tcol_sums = np.sum(co_occurrence_matrix, axis=0)\n","\n","\t# Total co-occurrences\n","\tN = np.sum(co_occurrence_matrix)\n","\n","\tif (N==0):\n","\t\treturn 0,0\n","\n","\t# Calculate pi and pj\n","\tpi = row_sums / N\n","\tpj = col_sums / N\n","\n","\treturn pi, pj\n","\n","\n","# Calculate pi and pj\n","pi, pj = calculate_probability(cocrmat)\n","\n","# %% [markdown]\n","# Generating the Positive Pointwise Mutual Information (PPMI) matrix from the Co-Occurance matrix\n","\n","# %%\n","\n","def gen_ppmi_matrix(co_occurrence_matrix):\n","\tppmi_matrix = np.zeros((len(vocab), len(vocab)))\n","\n","\trow_sums = np.sum(co_occurrence_matrix, axis=1)\n","\tfor i in tqdm(range(len(vocab))):\n","\t\tfor j in range(len(vocab)):\n","\n","\t\t\tif (row_sums[i] == 0 or co_occurrence_matrix[i][j] == 0):\n","\t\t\t\tppmi_matrix[i][j] = 0\n","\t\t\t\tcontinue\n","\t\t\tpij = ((co_occurrence_matrix[i][j]))/row_sums[i]\n","\t\t\tppmi_matrix[i][j] = max(0, math.log2(pij/(pi[i]*pj[j])))\n","\n","\treturn ppmi_matrix\n","\n","\n","ppmi_matrix = gen_ppmi_matrix(cocrmat)\n","\n","# %% [markdown]\n","# Functions for calculating similar words\n","\n","# %%\n","def calc_norm(vec):\n","\tsum_of_squares = sum(x**2 for x in vec)\n","\treturn math.sqrt(sum_of_squares)\n","\n","\n","def cosine_similarity(vec1, vec2):\n","\tv1 = list(vec1)\n","\tv2 = list(vec2)\n","\n","\tdot_product = (0.0)\n","\n","\tfor i in range(len(v1)):\n","\t\ttemp = dot_product\n","\t\tdot_product += (v1[i]*v2[i])\n","\t# print(dot_product)\n","\tnorm_vec1 = calc_norm(v1)\n","\tnorm_vec2 = calc_norm(v2)\n","\treturn dot_product / (norm_vec1 * norm_vec2)\n","\n","\n","def reshape_top(words, extra):\n","\tlow = 0\n","\thigh = len(words) - 1\n","\n","\twhile low <= high:\n","\t\tmid = (low + high) // 2\n","\t\tif words[mid][1] < extra[1]:\n","\t\t\tlow = mid + 1\n","\t\telif words[mid][1] > extra[1]:\n","\t\t\thigh = mid - 1\n","\t\telse:\n","\t\t\tbreak\n","\n","\twords.insert(low, extra)\n","\treturn words[1:]\n","\n","\n","def find_similar_words(target_word, ppmi_matrix, top_n=10):\n","\ttop_n += 1\n","\tif target_word not in vocab:\n","\t\tprint(\"Target word not found in the vocabulary.\")\n","\t\treturn\n","\n","\ttarget_index = vocab_pos[target_word]\n","\ttarget_vector = ppmi_matrix[target_index]\n","\n","\tsimilarities = [(vocab_idx[0], 0.0) for _ in range(top_n)]\n","\n","\tfor i, vector in enumerate(ppmi_matrix):\n","\t\tsim = cosine_similarity(target_vector, vector)\n","\t\tsimilarities = reshape_top(similarities, (vocab_idx[i], sim))\n","\n","\tsimilarities.reverse()\n","\n","\treturn similarities[1:]"]},{"cell_type":"markdown","metadata":{"id":"lX1pssku9dnq"},"source":["Generating the Top 15 words and choosing the Top 10 nouns from them"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"T0zW0Tt69dnq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 15 popular words :  ['रूप', 'हिप्पोकैम्पस', 'उपहार', 'नहीं', 'राज्य', 'ओडिन', 'बच्चों', 'भारत', 'ओलंपिक', 'स्मृति', 'नाम', 'ईसाई', 'विशेष', 'प्रकार', 'क्रिसमस']\n","Top 10 popular nouns :  ['रूप', 'हिप्पोकैम्पस', 'उपहार', 'राज्य', 'ओडिन', 'बच्चों', 'भारत', 'ओलंपिक', 'स्मृति', 'ईसाई']\n"]}],"source":["top_15 = vocab_counts.most_common(15)\n","top_15 = [i for i, _ in top_15]\n","print(\"Top 15 popular words : \", top_15)\n","\n","nouns = [top_15[0], top_15[1], top_15[2], top_15[4], top_15[5],\n","\t\ttop_15[6], top_15[7], top_15[8], top_15[9], top_15[11]]\n","print(\"Top 10 popular nouns : \", nouns)"]},{"cell_type":"markdown","metadata":{"id":"Imp4ooDa9dnq"},"source":["Sequential Processing - Displaying similar words for the nouns"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"aMhNqDNs9dnq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Words similar to 'रूप':\n","\tनहीं: 0.9487072218611307\n","\tउन्होंने: 0.930062101338945\n","\tसबसे: 0.9295931282106806\n","\tनाम: 0.9277516621623244\n","\tकारण: 0.9259441237081271\n","\tशामिल: 0.9186821937048143\n","\tकाम: 0.9028323314003853\n","\tप्राप्त: 0.900039119634523\n","\tमुख्य: 0.8995005017423224\n","\tप्रमुख: 0.8914432497554596\n","Words similar to 'हिप्पोकैम्पस':\n","\tविभेदस्थानिक: 0.7207213286524589\n","\tभूमिकाहिप्पोकैम्पस: 0.7162927728740857\n","\tदिशानिर्देशन: 0.6929263481764726\n","\tभूमिकाा: 0.6427220666189857\n","\tभूमिकाे: 0.6323230290634051\n","\tभूमिकां: 0.6242357862046934\n","\tभूमिकाी: 0.5855576984290632\n","\tस्मृति: 0.3232409766622346\n","\tमेडियल: 0.32040773148090806\n","\tभूमिकारूप: 0.3168999478220528\n","Words similar to 'उपहार':\n","\tउत्पत्तिउपहार: 0.5085022245806068\n","\tसिंटरक्लास: 0.3055436794275975\n","\tउत्पत्तिर: 0.3023470627281466\n","\tमिलतेआधुनिक: 0.283018218268561\n","\tदिन: 0.26910517450294663\n","\tदेने: 0.26812977062060644\n","\tक्रिसमस: 0.2673538038063325\n","\tघर: 0.2647296588651374\n","\tबच्चों: 0.26410470799276714\n","\tलोगों: 0.26390195090873525\n","Words similar to 'राज्य':\n","\tभारत: 0.8729305925012122\n","\tक्षेत्र: 0.8465035109263751\n","\tनाम: 0.8342443086489281\n","\tसबसे: 0.8308133032091893\n","\tभारतीय: 0.8295564817036121\n","\tउन्होंने: 0.8293562248007981\n","\tरूप: 0.8216233973296809\n","\tप्रमुख: 0.8207424900814395\n","\tपूर्व: 0.8185902175978319\n","\tकारण: 0.8144561622058488\n","Words similar to 'ओडिन':\n","\tउत्पत्तिओडिन: 0.6522855784465458\n","\tस्लीप्निर: 0.42582073962275574\n","\tउत्पत्तिे: 0.4155384798637636\n","\tमिलतेआधुनिक: 0.39874814845521167\n","\tउत्पत्तिं: 0.37168888665354677\n","\tउत्पत्तिी: 0.3618948820044102\n","\tउत्पत्तिा: 0.3555425717418441\n","\tक्लॉज़: 0.34480649363858157\n","\tस्केल्डिक: 0.34433687559864856\n","\tबैगसेंट: 0.33543798591113394\n","Words similar to 'बच्चों':\n","\tलोगों: 0.6643253337046479\n","\tनहीं: 0.663691240900005\n","\tकाम: 0.6556784510774927\n","\tउन्होंने: 0.650467781795403\n","\tजीवन: 0.6502234481210714\n","\tक्योंकि: 0.648835834329534\n","\tकारण: 0.6478127849716541\n","\tव्यक्ति: 0.6467004501301563\n","\tरूप: 0.644546669203904\n","\tबच्चे: 0.6406502932930335\n","Words similar to 'भारत':\n","\tभारतीय: 0.9053601379936722\n","\tनाम: 0.8895812019251523\n","\tउन्होंने: 0.8862834568467449\n","\tसबसे: 0.8857861580421877\n","\tरूप: 0.8796752821498018\n","\tक्षेत्र: 0.8772403430953826\n","\tराज्य: 0.8729305925012122\n","\tनहीं: 0.872886012652209\n","\tप्रमुख: 0.8674636127054484\n","\tकारण: 0.8654279984495824\n","Words similar to 'ओलंपिक':\n","\tग्रीष्मकालीन: 0.6003660256152524\n","\tखेलों: 0.5787036050129142\n","\tपदक: 0.5030674994694859\n","\tशीतकालीन: 0.4929021877131747\n","\tचैंपियनशिप: 0.46275898769664237\n","\tटूर्नामेंट: 0.4564458559467478\n","\tटीम: 0.445487397977815\n","\tएथलीटों: 0.4411999095593929\n","\tशहरइतिहासप्रारंभिक: 0.4404667075854617\n","\tकप: 0.4388161798455879\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m noun \u001b[38;5;129;01min\u001b[39;00m nouns:\n\u001b[1;32m      2\u001b[0m \ttarget_word \u001b[38;5;241m=\u001b[39m noun\n\u001b[0;32m----> 3\u001b[0m \tsimilar_words \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppmi_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWords similar to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m word, similarity \u001b[38;5;129;01min\u001b[39;00m similar_words:\n","Cell \u001b[0;32mIn[15], line 103\u001b[0m, in \u001b[0;36mfind_similar_words\u001b[0;34m(target_word, vocab, ppmi_matrix, top_n)\u001b[0m\n\u001b[1;32m    100\u001b[0m similarities \u001b[38;5;241m=\u001b[39m [(vocab_idx[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(top_n)]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ppmi_matrix):\n\u001b[0;32m--> 103\u001b[0m \tsim \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \tsimilarities \u001b[38;5;241m=\u001b[39m reshape_top(similarities, (vocab_idx[i], sim))\n\u001b[1;32m    106\u001b[0m similarities\u001b[38;5;241m.\u001b[39mreverse()\n","Cell \u001b[0;32mIn[15], line 70\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(vec1, vec2)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print(dot_product)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m norm_vec1 \u001b[38;5;241m=\u001b[39m calc_norm(v1)\n\u001b[0;32m---> 70\u001b[0m norm_vec2 \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dot_product \u001b[38;5;241m/\u001b[39m (norm_vec1 \u001b[38;5;241m*\u001b[39m norm_vec2)\n","Cell \u001b[0;32mIn[15], line 55\u001b[0m, in \u001b[0;36mcalc_norm\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_norm\u001b[39m(vec):\n\u001b[0;32m---> 55\u001b[0m \tsum_of_squares \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39msqrt(sum_of_squares)\n","Cell \u001b[0;32mIn[15], line 55\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_norm\u001b[39m(vec):\n\u001b[0;32m---> 55\u001b[0m \tsum_of_squares \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m vec)\n\u001b[1;32m     56\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39msqrt(sum_of_squares)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for noun in nouns:\n","\ttarget_word = noun\n","\tsimilar_words = find_similar_words(target_word, ppmi_matrix)\n","\n","\tprint(f\"Words similar to '{target_word}':\")\n","\tfor word, similarity in similar_words:\n","\t\tprint(f\"\t{word}: {similarity}\")"]},{"cell_type":"markdown","metadata":{"id":"lxzveghJTtE-"},"source":["Parallel Processing - Displaying similar words for the nouns"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"JdK-4rIeTtE_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Words similar to 'रूप':\n","\tनहीं: 0.9487072218611307\n","\tउन्होंने: 0.930062101338945\n","\tसबसे: 0.9295931282106806\n","\tनाम: 0.9277516621623244\n","\tकारण: 0.9259441237081271\n","\tशामिल: 0.9186821937048143\n","\tकाम: 0.9028323314003853\n","\tप्राप्त: 0.900039119634523\n","\tमुख्य: 0.8995005017423224\n","\tप्रमुख: 0.8914432497554596\n","\n","Words similar to 'हिप्पोकैम्पस':\n","\tविभेदस्थानिक: 0.7207213286524589\n","\tभूमिकाहिप्पोकैम्पस: 0.7162927728740857\n","\tदिशानिर्देशन: 0.6929263481764726\n","\tभूमिकाा: 0.6427220666189857\n","\tभूमिकाे: 0.6323230290634051\n","\tभूमिकां: 0.6242357862046934\n","\tभूमिकाी: 0.5855576984290632\n","\tस्मृति: 0.3232409766622346\n","\tमेडियल: 0.32040773148090806\n","\tभूमिकारूप: 0.3168999478220528\n","\n","Words similar to 'उपहार':\n","\tउत्पत्तिउपहार: 0.5085022245806068\n","\tसिंटरक्लास: 0.3055436794275975\n","\tउत्पत्तिर: 0.3023470627281466\n","\tमिलतेआधुनिक: 0.283018218268561\n","\tदिन: 0.26910517450294663\n","\tदेने: 0.26812977062060644\n","\tक्रिसमस: 0.2673538038063325\n","\tघर: 0.2647296588651374\n","\tबच्चों: 0.26410470799276714\n","\tलोगों: 0.26390195090873525\n","\n","Words similar to 'राज्य':\n","\tभारत: 0.8729305925012122\n","\tक्षेत्र: 0.8465035109263751\n","\tनाम: 0.8342443086489281\n","\tसबसे: 0.8308133032091893\n","\tभारतीय: 0.8295564817036121\n","\tउन्होंने: 0.8293562248007981\n","\tरूप: 0.8216233973296809\n","\tप्रमुख: 0.8207424900814395\n","\tपूर्व: 0.8185902175978319\n","\tकारण: 0.8144561622058488\n","\n","Words similar to 'ओडिन':\n","\tउत्पत्तिओडिन: 0.6522855784465458\n","\tस्लीप्निर: 0.42582073962275574\n","\tउत्पत्तिे: 0.4155384798637636\n","\tमिलतेआधुनिक: 0.39874814845521167\n","\tउत्पत्तिं: 0.37168888665354677\n","\tउत्पत्तिी: 0.3618948820044102\n","\tउत्पत्तिा: 0.3555425717418441\n","\tक्लॉज़: 0.34480649363858157\n","\tस्केल्डिक: 0.34433687559864856\n","\tबैगसेंट: 0.33543798591113394\n","\n","Words similar to 'बच्चों':\n","\tलोगों: 0.6643253337046479\n","\tनहीं: 0.663691240900005\n","\tकाम: 0.6556784510774927\n","\tउन्होंने: 0.650467781795403\n","\tजीवन: 0.6502234481210714\n","\tक्योंकि: 0.648835834329534\n","\tकारण: 0.6478127849716541\n","\tव्यक्ति: 0.6467004501301563\n","\tरूप: 0.644546669203904\n","\tबच्चे: 0.6406502932930335\n","\n","Words similar to 'भारत':\n","\tभारतीय: 0.9053601379936722\n","\tनाम: 0.8895812019251523\n","\tउन्होंने: 0.8862834568467449\n","\tसबसे: 0.8857861580421877\n","\tरूप: 0.8796752821498018\n","\tक्षेत्र: 0.8772403430953826\n","\tराज्य: 0.8729305925012122\n","\tनहीं: 0.872886012652209\n","\tप्रमुख: 0.8674636127054484\n","\tकारण: 0.8654279984495824\n","\n","Words similar to 'ओलंपिक':\n","\tग्रीष्मकालीन: 0.6003660256152524\n","\tखेलों: 0.5787036050129142\n","\tपदक: 0.5030674994694859\n","\tशीतकालीन: 0.4929021877131747\n","\tचैंपियनशिप: 0.46275898769664237\n","\tटूर्नामेंट: 0.4564458559467478\n","\tटीम: 0.445487397977815\n","\tएथलीटों: 0.4411999095593929\n","\tशहरइतिहासप्रारंभिक: 0.4404667075854617\n","\tकप: 0.4388161798455879\n","\n","Words similar to 'स्मृति':\n","\tरूप: 0.4702648229504565\n","\tजी: 0.4693870587627268\n","\tकार्य: 0.46535209256639165\n","\tजीवन: 0.4625475529793179\n","\tनहीं: 0.46217090340980305\n","\tव्यक्ति: 0.46166098121647886\n","\tअनेक: 0.46054987368584827\n","\tकरती: 0.46045396869057326\n","\tसाहित्य: 0.45985590074812727\n","\tकारण: 0.4581667484187002\n","\n","Words similar to 'ईसाई':\n","\tधर्म: 0.5871900068538051\n","\tधार्मिक: 0.5419101660492776\n","\tलोगों: 0.5295292818111683\n","\tइस्लाम: 0.5289899662404429\n","\tचर्च: 0.5256747559229747\n","\tमुस्लिम: 0.5215400856086\n","\tकैथोलिक: 0.5093026061994147\n","\tसमुदाय: 0.5059290630721052\n","\tजीवन: 0.5030946902124819\n","\tसमाज: 0.5030259563529063\n","\n"]}],"source":["\n","def similar_noun(noun,num,return_dict):\n","\tsimilars=\"\"\n","\n","\ttarget_word = noun\n","\tsimilar_words = find_similar_words(target_word, vocab, ppmi_matrix)\n","\n","\tsimilars+=(f\"Words similar to '{target_word}':\\n\")\n","\tfor word, similarity in similar_words:\n","\t\tsimilars+=(f\"\t{word}: {similarity}\\n\")\n","\n","\treturn_dict[num]=similars\n","\n","return_dict=multiprocessing.Manager().dict()\n","jobs=[]\n","\n","for i in range(10):\n","\tp=multiprocessing.Process(target=similar_noun, args=(nouns[i],i,return_dict,))\n","\tjobs.append(p)\n","\tp.start()\n","\n","for job in jobs:\n","\tjob.join()\n","\n","for i in range(10):\n","\tprint(return_dict[i])\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
