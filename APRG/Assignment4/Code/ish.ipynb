{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/Python_Installation/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "from wiki_dump_reader import Cleaner , iterate\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from nltk import ngrams, word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def runtime(func):\n",
    "\tdef wrapper(*args, **kwargs):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tresult = func(*args, **kwargs)\n",
    "\t\tend_time = time.time()\n",
    "\t\tprint(f\"Time taken by {func.__name__}: {end_time - start_time} seconds\")\n",
    "\t\treturn result\n",
    "\treturn wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_location(func):\n",
    "\tdef wrapper(*args, **kwargs):\n",
    "\t\tprint(f\"Location of {func.__name__}: {id(func)}\")\n",
    "\t\treturn func(*args, **kwargs)\n",
    "\treturn wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime\n",
    "@memory_location\n",
    "def create_corpus():\n",
    "\tcorpus_file = 'Hindi_Corpus.txt'\n",
    "\tcorpus_limit = 232729\n",
    "\tpage_count = 0\n",
    "\tcleaner = Cleaner()  # Assuming Cleaner class is imported or defined elsewhere.\n",
    "\t\n",
    "\t# Open the output file for writing\n",
    "\twith open(corpus_file, 'w', encoding='utf-8') as output:\n",
    "\t\tbar = tqdm(total=corpus_limit)  # Initialize the progress bar\n",
    "\t\tfor title, text in iterate('hiwiki-latest-pages-articles.xml'):  \n",
    "\t\t\ttext = cleaner.clean_text(text)\n",
    "\t\t\tcleaned_text, _ = cleaner.build_links(text)\n",
    "\t\t\toutput.write(title + '\\n' + cleaned_text + '\\n')\n",
    "\t\t\tpage_count += 1\n",
    "\t\t\tif page_count % 1000 == 0:\n",
    "\t\t\t\tbar.update(1000)  # Update progress bar every 1000 pages\n",
    "\t\tbar.close() \n",
    "\t\toutput.close()  # Close the output file\n",
    "\tprint(f\"\\nPage count = {page_count}\")  # Print total page count after processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stop_words():\n",
    "    \"\"\"\n",
    "    Create a list of stop words from a file named 'stopwords.txt'.\n",
    "\n",
    "    This function reads the stop words from the file, strips newline characters,\n",
    "    and splits the words by spaces to create a list of stop words.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of stop words.\n",
    "    \n",
    "    Raises:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    with open('stopwords.txt', 'r', encoding='utf-8') as stop:\n",
    "        y = stop.readlines()\n",
    "    x = []\n",
    "    for element in y:\n",
    "        element = element.strip('\\n')\n",
    "        x.extend(element.split(' '))\n",
    "    return x\n",
    "\n",
    "\n",
    "stop_words=create_stop_words()\n",
    "\n",
    "def remove_stop_words(string):\n",
    "    \"\"\"\n",
    "    Remove stop words from a given string.\n",
    "\n",
    "    This function takes a string as input, splits it into words, and removes\n",
    "    any words that are found in a predefined list of stop words. It then joins\n",
    "    the remaining words back into a single string and returns it.\n",
    "\n",
    "    Args:\n",
    "        string (str): The input string from which stop words are to be removed.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string with stop words removed.\n",
    "    \n",
    "    Raises:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    l = string.split()  # Split the input string into a list of words\n",
    "    return_list = []\n",
    "    for x in l:\n",
    "        if x not in stop_words:  # Check if the word is not in the stop_words list\n",
    "            return_list.append(x)  # If not, add it to the return_list\n",
    "    return ' '.join(return_list)  # Join the words in return_list back into a string and return it\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_foreign(x):\n",
    "    \"\"\"\n",
    "    Remove foreign characters from a given string.\n",
    "\n",
    "    This function takes a string as input and removes any characters that are not\n",
    "    part of the Devanagari script, which is commonly used for writing languages like Hindi, Sanskrit, etc.\n",
    "    \n",
    "    Args:\n",
    "        x (str): The input string from which foreign characters are to be removed.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string with foreign characters removed.\n",
    "    \n",
    "    Raises:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    string = x.split(' ')  # Split the input string into a list of words\n",
    "    y = [(re.compile(r'[\\u0901-\\u0939\\u093C-\\u094D\\u0950-\\u0954\\u0958-\\u0963\\u097B-\\u097F]')).findall(s) for s in string]\n",
    "    z = [''.join(s) for s in y]  # Join the characters found in each word back into a string\n",
    "    w = ' '.join(z)  # Join the resulting strings back into a single string\n",
    "    return w  # Return the string with foreign characters removed\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "@runtime\n",
    "@memory_location\n",
    "def pre(source, destination):\n",
    "    \"\"\"\n",
    "    Preprocess a source text file and save the result to a destination file.\n",
    "\n",
    "    This function reads text from the source file, removes foreign characters\n",
    "    and stop words, and writes the preprocessed text to the destination file.\n",
    "    It also updates a progress bar to show the processing progress.\n",
    "\n",
    "    Args:\n",
    "        source (str): The path to the source text file.\n",
    "        destination (str): The path to save the preprocessed text file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    with open(source, 'r', encoding='utf-8') as input:\n",
    "        with open(destination, 'w', encoding='utf-8') as output:\n",
    "            bar = tqdm(total=5000000)  # Assuming 5000000 is the total number of lines\n",
    "            for line in input:\n",
    "                string = line.replace('\\n', '')\n",
    "                string = remove_foreign(string)\n",
    "                string = remove_stop_words(string)\n",
    "                output.write(string)\n",
    "                line_count += 1\n",
    "                if line_count % 10000 == 0:\n",
    "                    bar.update(10000)  # Update progress bar every 10000 lines\n",
    "            bar.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre('Hindi_Corpus.txt', 'ProcessedCorpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "min_vocab=0\n",
    "\n",
    "def list_of_words():\n",
    "\twith open('ProcessedCorpus.txt', 'r', encoding='utf-8') as r:\n",
    "\t\ttext = r.read().split()\n",
    "\tword_counts = Counter(text)\n",
    "\ttext = [word for word in tqdm(text) if word_counts[word] > min_vocab]  \n",
    "\treturn text\n",
    "\n",
    "def gen_distinct_vocab():\n",
    "\twith open('ProcessedCorpus.txt', 'r', encoding='utf-8') as r:\n",
    "\t\ttext = r.read().split()\n",
    "\t\tcounter = Counter(text)\n",
    "\t\treduced_vocab = [item for item, count in counter.items() if count > min_vocab]\n",
    "\t\ttext_set = set(reduced_vocab)\n",
    "\t\tglobal vocabulary_size\n",
    "\t\tvocabulary_size = len(text_set)\n",
    "\treturn list(text_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3944/3944 [00:00<00:00, 8034159.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global words_list\n",
    "words_list=list_of_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=gen_distinct_vocab()\n",
    "vocabulary_size = len(vocab)\n",
    "tokens = word_tokenize(' '.join(words_list))\n",
    "grams = ngrams(tokens, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens is:  3944\n",
      "Size of the vocabulary:  1774\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens is: \", len(tokens))\n",
    "print(\"Size of the vocabulary: \", vocabulary_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of create_matrix: 125689201869824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3939it [00:00, 6034.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by wrapper: 0.6548962593078613 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matrix = np.zeros((len(vocab),len(vocab)),dtype=np.int64)\n",
    "\n",
    "@runtime\n",
    "@memory_location\n",
    "def create_matrix():\n",
    "\n",
    "    for x in tqdm(grams):\n",
    "    \n",
    "        \n",
    "        if x[0] in vocab:\n",
    "            if x[1] in vocab:\n",
    "                matrix[vocab.index(x[0])][vocab.index(x[1])] += 5\n",
    "            if x[2] in vocab:\n",
    "                matrix[vocab.index(x[0])][vocab.index(x[2])] += 4\n",
    "            if x[3] in vocab:\n",
    "                matrix[vocab.index(x[0])][vocab.index(x[3])] += 3\n",
    "            if x[4] in vocab:\n",
    "                matrix[vocab.index(x[0])][vocab.index(x[4])] += 2\n",
    "            if x[5] in vocab:\n",
    "                matrix[vocab.index(x[0])][vocab.index(x[5])] += 1\n",
    "        if x[5] in vocab:\n",
    "            if x[1] in vocab:\n",
    "                matrix[vocab.index(x[5])][vocab.index(x[1])] += 2\n",
    "            if x[2] in vocab:\n",
    "                matrix[vocab.index(x[5])][vocab.index(x[2])] += 3\n",
    "            if x[3] in vocab:\n",
    "                matrix[vocab.index(x[5])][vocab.index(x[3])] += 4\n",
    "            if x[4] in vocab:\n",
    "                matrix[vocab.index(x[5])][vocab.index(x[4])] += 5\n",
    "            if x[0] in vocab:\n",
    "                matrix[vocab.index(x[5])][vocab.index(x[0])] += 1\n",
    "\n",
    "        \n",
    "create_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "@runtime\n",
    "@memory_location\n",
    "def calculate_probability(matrix):\n",
    "\t\n",
    "\trow_sums = np.sum(matrix, axis=1)\n",
    "\tcol_sums = np.sum(matrix, axis=0)\n",
    "\n",
    "\tN = np.sum(matrix)\n",
    "\n",
    "\tif(N==0):\n",
    "\t\treturn 0,0\n",
    "\n",
    "\tglobal pi,pj\n",
    "\n",
    "\tpi = row_sums / N\n",
    "\tpj = col_sums / N\n",
    "\n",
    " \n",
    " \n",
    "@runtime\n",
    "@memory_location\n",
    "def gen_ppmi_matrix(matrix):\n",
    "\tco_occurrence_matrix=matrix\n",
    " \n",
    "\tppmi = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "\trow_sums = np.sum(co_occurrence_matrix, axis=1)\n",
    "\tfor i in tqdm(range(len(vocab))):\n",
    "\t\tfor j in range(len(vocab)):\n",
    "\n",
    "\t\t\tif (row_sums[i] == 0 or co_occurrence_matrix[i][j] == 0):\n",
    "\t\t\t\tppmi[i][j] = 0\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tpij = ((co_occurrence_matrix[i][j]))/row_sums[i]\n",
    "\t\t\tppmi[i][j] = max(0, math.log2(pij/(pi[i]*pj[j])))\n",
    "\n",
    "\treturn ppmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of calculate_probability: 125689201870304\n",
      "Time taken by wrapper: 0.004347801208496094 seconds\n",
      "Location of gen_ppmi_matrix: 125689201870464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1774/1774 [00:00<00:00, 1777.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by wrapper: 1.001314640045166 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_probability(matrix)\n",
    "ppmi_matrix=gen_ppmi_matrix(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3944/3944 [00:00<00:00, 4113985.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(list_of_words())\n",
    "common_elements = counter.most_common(10)\n",
    "most_common_elements=[a for (a,_) in common_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nearest_seq: 125689201872224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1773/1773 [00:00<00:00, 1801.05it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1905.54it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1913.35it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1870.39it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1781.80it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1851.84it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1918.24it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1725.97it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1703.79it/s]\n",
      "100%|██████████| 1773/1773 [00:00<00:00, 1893.41it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by wrapper: 9.753339290618896 seconds\n",
      "{'हिन्दी': [('भाषा', 0.3828333162560839), ('भारत', 0.37609673574581554), ('रूप', 0.3477976068694602), ('भारतीय', 0.3284881293616273), ('उर्दू', 0.3280451644345689), ('प्रयोग', 0.305675297015081), ('भाषाओं', 0.28105872329174497), ('लोगों', 0.2688475790890009), ('बोली', 0.2665104863461141), ('आधुनिक', 0.2558838703714098), ('संख्या', 0.2550382375749371)], 'ॐ': [('नमः', 0.8482123197195954), ('विनायकाय', 0.6552663538005526), ('सिद्धि', 0.6499178515580774), ('समर्पयामि', 0.6134782932775708), ('श्री', 0.4270907762080836), ('पूजयामि', 0.3958441800594761), ('महा', 0.38962230677027127), ('दन्ताय', 0.35423902377597016), ('राजाय', 0.3495139749613974), ('विघ्न', 0.3485530702997846), ('पुष्पं', 0.3267200126202506)], 'भाषा': [('रूप', 0.42782447626726144), ('हिन्दी', 0.3828333162560839), ('शब्द', 0.29446673259386297), ('प्रयोग', 0.29271778384468583), ('हिन्दुस्तानी', 0.2876924021522872), ('उर्दू', 0.287402620434434), ('भारत', 0.2850153185172091), ('वाली', 0.2828711578671664), ('विश्व', 0.2761608389094854), ('अरबी', 0.2725472719171115), ('फ़ारसी', 0.2670703698000809)], 'नमः': [('ॐ', 0.8482123197195954), ('विनायकाय', 0.7017415988243507), ('सिद्धि', 0.6586821551879464), ('समर्पयामि', 0.6151243405240627), ('पूजयामि', 0.41709978296050404), ('पुष्पं', 0.3929181366941143), ('दन्ताय', 0.37222153234341576), ('राजाय', 0.3672921878275748), ('विघ्न', 0.36595493865478085), ('पूजां', 0.35288714583871356), ('गणेश', 0.3371613041223527)], 'लिपि': [('देवनागरी', 0.5504214029463007), ('लिपियों', 0.3931885884941031), ('नागरी', 0.33784971896076543), ('शताब्दी', 0.3348573599077869), ('लिखा', 0.31296486278192936), ('अक्षरात्मक', 0.29976914337621363), ('ब्राह्मी', 0.29902529633938857), ('अंकित', 0.2894853001224914), ('सबसे', 0.2706626354975069), ('लिखी', 0.25156007115479767), ('दृष्टि', 0.2500333323998329)], 'देवनागरी': [('लिपि', 0.5504214029463007), ('अंकित', 0.36533451234857495), ('शताब्दी', 0.3171701116236029), ('लिपियों', 0.3033148473703143), ('सिक्कों', 0.3003820528037952), ('प्रथम', 0.28548957219446813), ('लिखने', 0.27582978526127616), ('लेख', 0.26951556309705244), ('सबसे', 0.26626848008729864), ('राजा', 0.2647509197980742), ('सिक्के', 0.25798991981326497)], 'रूप': [('भाषा', 0.42782447626726144), ('हिन्दी', 0.3477976068694602), ('उर्दू', 0.27278803590013984), ('शब्द', 0.26704489476961857), ('प्रयोग', 0.2448279877767448), ('अरबी', 0.24349864809079036), ('मानकीकृत', 0.23358672626149832), ('भारतीय', 0.23275339950655244), ('सबसे', 0.23031861534373677), ('वाली', 0.22448145811840334), ('लिपि', 0.2228935122441001)], 'शब्द': [('संस्कृत', 0.36424300110071495), ('अर्थ', 0.34297084668293937), ('बना', 0.3324033087558802), ('फ़ारसीअरबी', 0.3134133857077537), ('भाषा', 0.29446673259386297), ('शब्दों', 0.29242528422221775), ('अरबी', 0.28415268659961734), ('रूप', 0.26704489476961857), ('सिन्धु', 0.26491571196469405), ('प्रयोग', 0.26155669058386033), ('देशज', 0.26079394290026686)], 'संस्कृत': [('शब्द', 0.36424300110071495), ('शब्दों', 0.3367480283678111), ('नहीं', 0.2948669918582967), ('फ़ारसी', 0.28497043852297044), ('लिखे', 0.2752081249881326), ('परन्तु', 0.2602220495196953), ('उच्चारण', 0.25727186485266584), ('बिना', 0.2559109573759727), ('मराठी', 0.2554855855024246), ('शब्दावली', 0.25229366894925126), ('तत्सम', 0.2501108476358384)], 'विनायकाय': [('सिद्धि', 0.9461723909124189), ('नमः', 0.7017415988243507), ('ॐ', 0.6552663538005526), ('समर्पयामि', 0.5755634203756774), ('पूजां', 0.379971333261694), ('पुष्प', 0.3199608911831442), ('पत्र', 0.30650655083100836), ('समर्पयामिउत्तर', 0.3005667672962459), ('गणेश', 0.29231251810874004), ('दीपं', 0.2913952822727388), ('दर्शयामि', 0.2905022674365624)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def insert_into_sorted_list(sorted_list, element):\n",
    "    index = 0\n",
    "    while index < len(sorted_list) and sorted_list[index][1] > element[1]:\n",
    "        index += 1\n",
    "    sorted_list.insert(index, element)\n",
    "    return sorted_list[:-1]\n",
    "\n",
    "def cosine(a,b):\n",
    "        mag_a = math.sqrt(sum(component ** 2 for component in a))\n",
    "        mag_b = math.sqrt(sum(component ** 2 for component in b))\n",
    "        dot_product = sum(ai * bi for ai, bi in zip(a, b))\n",
    "        if mag_a == 0 or mag_b ==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return dot_product/(mag_a*mag_b)\n",
    "\n",
    "def find_nearest_neighbor_of_noun(index):\n",
    "    l=[(vocab[0],(cosine(ppmi_matrix[index], ppmi_matrix[0]))) for _ in range(11)]\n",
    "    for i in tqdm(range(1,len(vocab))):\n",
    "        if i!=index:\n",
    "            if cosine(ppmi_matrix[index],ppmi_matrix[i])>l[10][1]:\n",
    "                l=insert_into_sorted_list(l,(vocab[i],(cosine(ppmi_matrix[index], ppmi_matrix[i]))))\n",
    "    return l\n",
    "\n",
    "nearest_neighbour_dict={}\n",
    "\n",
    "@runtime\n",
    "@memory_location\n",
    "def nearest_seq():\n",
    "    for x in tqdm(most_common_elements):\n",
    "        nearest_neighbour_dict[x]=find_nearest_neighbor_of_noun(vocab.index(x))\n",
    "\n",
    "nearest_seq()\n",
    "\n",
    "print(nearest_neighbour_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of create_matrix_p: 125689200098208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3939it [00:11, 331.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by wrapper: 11.890224695205688 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "n = vocabulary_size\n",
    "p_mat = multiprocessing.Array('d', n*n)\n",
    "\n",
    "def compile_grams(x,p_mat):\n",
    "    leng=len(vocab)\n",
    "    \n",
    "\n",
    "    if x[0] in vocab:\n",
    "        if x[1] in vocab:\n",
    "            p_mat[vocab.index(x[0])*leng+vocab.index(x[1])] += 5\n",
    "        if x[2] in vocab:\n",
    "            p_mat[vocab.index(x[0])*leng+vocab.index(x[2])] += 4\n",
    "        if x[3] in vocab:\n",
    "            p_mat[vocab.index(x[0])*leng+vocab.index(x[3])] += 3\n",
    "        if x[4] in vocab:\n",
    "            p_mat[vocab.index(x[0])*leng+vocab.index(x[4])] += 2\n",
    "        if x[5] in vocab:\n",
    "            p_mat[vocab.index(x[0])*leng+vocab.index(x[5])] += 1\n",
    "    if x[5] in vocab:\n",
    "        if x[1] in vocab:\n",
    "            p_mat[vocab.index(x[5])*leng+vocab.index(x[1])] += 2\n",
    "        if x[2] in vocab:\n",
    "            p_mat[vocab.index(x[5])*leng+vocab.index(x[2])] += 3\n",
    "        if x[3] in vocab:\n",
    "            p_mat[vocab.index(x[5])*leng+vocab.index(x[3])] += 4\n",
    "        if x[4] in vocab:\n",
    "            p_mat[vocab.index(x[5])*leng+vocab.index(x[4])] += 5\n",
    "        if x[0] in vocab:\n",
    "            p_mat[vocab.index(x[5])*leng+vocab.index(x[0])] += 1\n",
    "\n",
    "@runtime\n",
    "@memory_location\n",
    "def create_matrix_p(p_mat):\n",
    "    grams = ngrams(tokens,6)\n",
    "\n",
    "    jobs=[]\n",
    "\n",
    "    for x in tqdm(grams):\n",
    "        p=multiprocessing.Process(target=compile_grams, args=(x,p_mat,))\n",
    "        p.start()\n",
    "        jobs.append(p)\n",
    "\n",
    "    for job in jobs:\n",
    "        job.join()\n",
    "\n",
    "create_matrix_p(p_mat)\n",
    "\n",
    "p_matrix = np.zeros((n,n),dtype=np.int64)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        p_matrix[i][j]=p_mat[i*n+j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of parallel_nearest: 125689200098368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1773/1773 [00:01<00:00, 1186.49it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1199.88it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1161.72it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1104.26it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1075.29it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1057.44it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 1069.71it/s]\n",
      "100%|██████████| 1773/1773 [00:01<00:00, 998.21it/s] \n",
      "100%|██████████| 1773/1773 [00:01<00:00, 998.07it/s] \n",
      "100%|██████████| 1773/1773 [00:01<00:00, 973.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by wrapper: 1.880664587020874 seconds\n",
      "Words similar to  हिन्दी  :\n",
      "   भाषा  :  0.3828333162560839\n",
      "   भारत  :  0.37609673574581554\n",
      "   रूप  :  0.3477976068694602\n",
      "   भारतीय  :  0.3284881293616273\n",
      "   उर्दू  :  0.3280451644345689\n",
      "   प्रयोग  :  0.305675297015081\n",
      "   भाषाओं  :  0.28105872329174497\n",
      "   लोगों  :  0.2688475790890009\n",
      "   बोली  :  0.2665104863461141\n",
      "   आधुनिक  :  0.2558838703714098\n",
      "   संख्या  :  0.2550382375749371\n",
      "Words similar to  ॐ  :\n",
      "   नमः  :  0.8482123197195954\n",
      "   विनायकाय  :  0.6552663538005526\n",
      "   सिद्धि  :  0.6499178515580774\n",
      "   समर्पयामि  :  0.6134782932775708\n",
      "   श्री  :  0.4270907762080836\n",
      "   पूजयामि  :  0.3958441800594761\n",
      "   महा  :  0.38962230677027127\n",
      "   दन्ताय  :  0.35423902377597016\n",
      "   राजाय  :  0.3495139749613974\n",
      "   विघ्न  :  0.3485530702997846\n",
      "   पुष्पं  :  0.3267200126202506\n",
      "Words similar to  भाषा  :\n",
      "   रूप  :  0.42782447626726144\n",
      "   हिन्दी  :  0.3828333162560839\n",
      "   शब्द  :  0.29446673259386297\n",
      "   प्रयोग  :  0.29271778384468583\n",
      "   हिन्दुस्तानी  :  0.2876924021522872\n",
      "   उर्दू  :  0.287402620434434\n",
      "   भारत  :  0.2850153185172091\n",
      "   वाली  :  0.2828711578671664\n",
      "   विश्व  :  0.2761608389094854\n",
      "   अरबी  :  0.2725472719171115\n",
      "   फ़ारसी  :  0.2670703698000809\n",
      "Words similar to  नमः  :\n",
      "   ॐ  :  0.8482123197195954\n",
      "   विनायकाय  :  0.7017415988243507\n",
      "   सिद्धि  :  0.6586821551879464\n",
      "   समर्पयामि  :  0.6151243405240627\n",
      "   पूजयामि  :  0.41709978296050404\n",
      "   पुष्पं  :  0.3929181366941143\n",
      "   दन्ताय  :  0.37222153234341576\n",
      "   राजाय  :  0.3672921878275748\n",
      "   विघ्न  :  0.36595493865478085\n",
      "   पूजां  :  0.35288714583871356\n",
      "   गणेश  :  0.3371613041223527\n",
      "Words similar to  लिपि  :\n",
      "   देवनागरी  :  0.5504214029463007\n",
      "   लिपियों  :  0.3931885884941031\n",
      "   नागरी  :  0.33784971896076543\n",
      "   शताब्दी  :  0.3348573599077869\n",
      "   लिखा  :  0.31296486278192936\n",
      "   अक्षरात्मक  :  0.29976914337621363\n",
      "   ब्राह्मी  :  0.29902529633938857\n",
      "   अंकित  :  0.2894853001224914\n",
      "   सबसे  :  0.2706626354975069\n",
      "   लिखी  :  0.25156007115479767\n",
      "   दृष्टि  :  0.2500333323998329\n",
      "Words similar to  देवनागरी  :\n",
      "   लिपि  :  0.5504214029463007\n",
      "   अंकित  :  0.36533451234857495\n",
      "   शताब्दी  :  0.3171701116236029\n",
      "   लिपियों  :  0.3033148473703143\n",
      "   सिक्कों  :  0.3003820528037952\n",
      "   प्रथम  :  0.28548957219446813\n",
      "   लिखने  :  0.27582978526127616\n",
      "   लेख  :  0.26951556309705244\n",
      "   सबसे  :  0.26626848008729864\n",
      "   राजा  :  0.2647509197980742\n",
      "   सिक्के  :  0.25798991981326497\n",
      "Words similar to  रूप  :\n",
      "   भाषा  :  0.42782447626726144\n",
      "   हिन्दी  :  0.3477976068694602\n",
      "   उर्दू  :  0.27278803590013984\n",
      "   शब्द  :  0.26704489476961857\n",
      "   प्रयोग  :  0.2448279877767448\n",
      "   अरबी  :  0.24349864809079036\n",
      "   मानकीकृत  :  0.23358672626149832\n",
      "   भारतीय  :  0.23275339950655244\n",
      "   सबसे  :  0.23031861534373677\n",
      "   वाली  :  0.22448145811840334\n",
      "   लिपि  :  0.2228935122441001\n",
      "Words similar to  शब्द  :\n",
      "   संस्कृत  :  0.36424300110071495\n",
      "   अर्थ  :  0.34297084668293937\n",
      "   बना  :  0.3324033087558802\n",
      "   फ़ारसीअरबी  :  0.3134133857077537\n",
      "   भाषा  :  0.29446673259386297\n",
      "   शब्दों  :  0.29242528422221775\n",
      "   अरबी  :  0.28415268659961734\n",
      "   रूप  :  0.26704489476961857\n",
      "   सिन्धु  :  0.26491571196469405\n",
      "   प्रयोग  :  0.26155669058386033\n",
      "   देशज  :  0.26079394290026686\n",
      "Words similar to  संस्कृत  :\n",
      "   शब्द  :  0.36424300110071495\n",
      "   शब्दों  :  0.3367480283678111\n",
      "   नहीं  :  0.2948669918582967\n",
      "   फ़ारसी  :  0.28497043852297044\n",
      "   लिखे  :  0.2752081249881326\n",
      "   परन्तु  :  0.2602220495196953\n",
      "   उच्चारण  :  0.25727186485266584\n",
      "   बिना  :  0.2559109573759727\n",
      "   मराठी  :  0.2554855855024246\n",
      "   शब्दावली  :  0.25229366894925126\n",
      "   तत्सम  :  0.2501108476358384\n",
      "Words similar to  विनायकाय  :\n",
      "   सिद्धि  :  0.9461723909124189\n",
      "   नमः  :  0.7017415988243507\n",
      "   ॐ  :  0.6552663538005526\n",
      "   समर्पयामि  :  0.5755634203756774\n",
      "   पूजां  :  0.379971333261694\n",
      "   पुष्प  :  0.3199608911831442\n",
      "   पत्र  :  0.30650655083100836\n",
      "   समर्पयामिउत्तर  :  0.3005667672962459\n",
      "   गणेश  :  0.29231251810874004\n",
      "   दीपं  :  0.2913952822727388\n",
      "   दर्शयामि  :  0.2905022674365624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "neigh = multiprocessing.Manager().dict()\n",
    "\n",
    "def p_insert_into_sorted_list(sorted_list, element):\n",
    "\tindex = 0\n",
    "\twhile index < len(sorted_list) and sorted_list[index][1] > element[1]:\n",
    "\t\tindex += 1\n",
    "\tsorted_list.insert(index, element)\n",
    "\treturn sorted_list[:-1]\n",
    "\n",
    "def p_cosine(a,b):\n",
    "\t\tmag_a = math.sqrt(sum(component ** 2 for component in a))\n",
    "\t\tmag_b = math.sqrt(sum(component ** 2 for component in b))\n",
    "\t\tdot_product = sum(ai * bi for ai, bi in zip(a, b))\n",
    "\t\tif mag_a == 0 or mag_b ==0:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn dot_product/(mag_a*mag_b)\n",
    "\n",
    "def p_find_nearest_neighbor_of_noun(index,neigh):\n",
    "\tl=[(vocab[0],(p_cosine(ppmi_matrix[index], ppmi_matrix[0]))) for _ in range(11)]\n",
    "\tfor i in tqdm(range(1,n)):\n",
    "\t\tif i!=index:\n",
    "\t\t\tif p_cosine(ppmi_matrix[index],ppmi_matrix[i])>l[10][1]:\n",
    "\t\t\t\tl=p_insert_into_sorted_list(l,(vocab[i],(p_cosine(ppmi_matrix[index], ppmi_matrix[i]))))\n",
    "\n",
    "\tneigh[vocab[index]]=l\n",
    "\n",
    "@runtime\n",
    "@memory_location\n",
    "def parallel_nearest():\n",
    "\tjobs=[]\n",
    "\tfor x in (most_common_elements):\n",
    "\t\tp=multiprocessing.Process(target=p_find_nearest_neighbor_of_noun, args=(vocab.index(x),neigh,))\n",
    "\t\tp.start()\n",
    "\t\tjobs.append(p)\n",
    "\n",
    "\tfor job in jobs:\n",
    "\t\tjob.join()\n",
    "\t\t\n",
    "parallel_nearest()\n",
    "\n",
    "neighbour={}\n",
    "\n",
    "for elem in most_common_elements:\n",
    "\tneighbour[elem]=neigh[elem]\n",
    "\n",
    "for i in neighbour:\n",
    "\tprint(\"Words similar to \",i,\" :\")\n",
    "\tfor j in neighbour[i]:\n",
    "\t\tprint (\"  \",j[0],\" : \",j[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
