{"cells":[{"cell_type":"markdown","metadata":{"id":"2qMmJSy19dnf"},"source":["Importing Local File Paths"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20574,"status":"ok","timestamp":1713693271975,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"9_zvOPTY9dng","outputId":"35451697-2b85-4b48-e4a0-abc1fdef5874"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","\n","corpus_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/HindiCorpus.txt\"\n","preprocessed_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/ProcessedCorpus.txt\"\n","xml_file = \"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/hiwiki-latest-pages-articles.xml\"\n","stop_words_file=\"/content/drive/MyDrive/Colab Notebooks/AnuragBMC202309_Assignment04/stopwords.txt\"\n","\n","corpus_limit=232729\n","preprocess_limit=4232433\n","gramms_limit=38735257"]},{"cell_type":"markdown","metadata":{"id":"_TW8s3RU9dni"},"source":["Importing necessary libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13620,"status":"ok","timestamp":1713693285592,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"i-PPPakT9dni","outputId":"091e48d1-0433-45a0-810f-cb58b87a69ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wiki_dump_reader\n","  Downloading wiki-dump-reader-0.0.4.tar.gz (3.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wiki_dump_reader\n","  Building wheel for wiki_dump_reader (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wiki_dump_reader: filename=wiki_dump_reader-0.0.4-py3-none-any.whl size=3983 sha256=a323e8f6f133e7be20c15cce2d6dee11c1fdd28678be51470e7c408e31309c87\n","  Stored in directory: /root/.cache/pip/wheels/78/81/3d/463b7f906f65d3e9e43db8446ebc5fb719bf1777a40b411cd2\n","Successfully built wiki_dump_reader\n","Installing collected packages: wiki_dump_reader\n","Successfully installed wiki_dump_reader-0.0.4\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["from collections import Counter, defaultdict\n","!pip install wiki_dump_reader\n","from wiki_dump_reader import Cleaner, iterate\n","\n","import string\n","\n","from nltk import ngrams, word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","import numpy as np\n","from tqdm import tqdm\n","import math"]},{"cell_type":"markdown","metadata":{"id":"rWapj5jJ9dnj"},"source":["Creating the corpus from the Wiki Dump Reader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1253255,"status":"ok","timestamp":1712491237896,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"XHElYyqv9dnj","outputId":"00cac879-240e-496b-c8ca-1e7383627f0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 232000/232729 [20:39<00:03, 187.14it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Page count = 232728\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def write_corpus(corpus):\n","\n","\tpage_count = 0\n","\tcleaner = Cleaner()\n","\twith open(corpus, 'w', encoding='utf -8') as output:\n","\t\tpg_bar=tqdm(total=corpus_limit)\n","\t\tfor title, text in iterate(xml_file):\n","\t\t\ttext = cleaner.clean_text(text)\n","\t\t\tcleaned_text, _ = cleaner.build_links(text)\n","\t\t\toutput.write(title + '\\n' + cleaned_text + '\\n ')\n","\t\t\tpage_count += 1\n","\t\t\tif page_count % 1000 == 0:\n","\t\t\t\tpg_bar.update(1000)\n","\t\tpg_bar.close()\n","\t\toutput.close()\n","\tprint(f\"\\nPage count = {page_count}\")\n","\n","\n","write_corpus(corpus_file)"]},{"cell_type":"markdown","metadata":{"id":"1eI2UZf_9dnk"},"source":["Creating functions needed for Pre Processing the corpus"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":364,"status":"ok","timestamp":1713671752727,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"LZDQQokb9dnk"},"outputs":[],"source":["stop_words = []\n","\n","start = int('0x0900', 16)\n","end = int('0x097F', 16)\n","\n","num_start = int('0x0966', 16)\n","num_end = int('0x096F', 16)\n","\n","hindi_letters = [chr(code) for code in range(start, end + 1)]\n","hindi_letters.remove('॥')\n","hindi_letters.remove('।')\n","hindi_letters.remove('ॽ')\n","\n","hindi_numbers = [chr(code) for code in range(num_start, num_end + 1)]\n","\n","\n","def create_stop_words(file_path):\n","\ttry:\n","\t\twith open(file_path, 'r', encoding=\"utf-8\") as file:\n","\t\t\tfor line in file:\n","\t\t\t\tline=line.strip()\n","\t\t\t\twords=line.split(\" \")\n","\t\t\t\tfor word in words:\n","\t\t\t\t\tstop_words.append(word)\n","\texcept:\n","\t\tprint()\n","\n","\n","def remove_numbers(text):\n","\ttokens = list(text)\n","\tfiltered_tokens = []\n","\n","\tfor token in tokens:\n","\t\tif token not in hindi_numbers:\n","\t\t\tfiltered_tokens.append(token)\n","\n","\tresult = ''.join(filtered_tokens)\n","\treturn result\n","\n","\n","def remove_punctuation(text):\n","\ttranslator = str.maketrans('', '', string.punctuation)\n","\treturn text.translate(translator)\n","\n","\n","def remove_whitespace(text):\n","\treturn \" \".join(text.split())\n","\n","\n","create_stop_words(stop_words_file)"]},{"cell_type":"markdown","metadata":{"id":"HLuwTdjv9dnk"},"source":["Pre Processing the corpus for further analysis"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":796345,"status":"ok","timestamp":1713672738896,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"RtTD-68M9dnl","outputId":"11241d42-3051-4702-d6c3-fda072c8cf24"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 4230000/4232433 [16:21<00:00, 4310.10it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Lines processed = 4232432\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def preprocess_line(text):\n","\ttext = remove_whitespace(remove_punctuation(remove_numbers(text)))\n","\n","\twords = text.split(\" \")\n","\n","\t# Filter out foreign words\n","\tfiltered_tokens = []\n","\tfor word in words:\n","\t\tif word in stop_words:\n","\t\t\tcontinue\n","\n","\t\tbreaker = False\n","\t\tfor letter in word:\n","\t\t\tif letter not in hindi_letters:\n","\t\t\t\tbreaker = True\n","\t\t\t\tbreak\n","\n","\t\tif breaker:\n","\t\t\tcontinue\n","\n","\t\tfiltered_tokens.append(word)\n","\n","\t# Reassemble the text\n","\tprocessed_text = ' '.join(filtered_tokens)\n","\n","\treturn processed_text\n","\n","\n","def preprocess_corpus(source_file, destination_file):\n","\tline_count = 0\n","\twith open(source_file, 'r', encoding=\"utf-8\") as source:\n","\t\twith open(destination_file, 'w', encoding=\"utf-8\") as destination:\n","\t\t\tpg_bar=tqdm(total=preprocess_limit)\n","\t\t\tfor line in source:\n","\t\t\t\tdestination.write(preprocess_line(line))\n","\t\t\t\tline_count += 1\n","\t\t\t\tif line_count % 10000 == 0:\n","\t\t\t\t\tpg_bar.update(10000)\n","\t\t\tpg_bar.close()\n","\n","\tprint(f'\\nLines processed = {line_count}')\n","\n","preprocess_corpus(corpus_file, preprocessed_file)"]},{"cell_type":"markdown","metadata":{"id":"capAi0rL9dnn"},"source":["Functions for generating number of tokens and vocabulary"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":617,"status":"ok","timestamp":1713693287490,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"3Kz_gBkG9dnn"},"outputs":[],"source":["\n","def gen_token_count(file):\n","\ttoken_len = 0\n","\twith open(file, 'r', encoding=\"utf-8\") as f:\n","\t\tfor line in f:\n","\t\t\tline=line.replace('\\n','')\n","\t\t\tspace_count = 0\n","\t\t\tfor char in line:\n","\t\t\t\tif char == ' ':\n","\t\t\t\t\tspace_count += 1\n","\n","\t\t\ttoken_len += space_count+1\n","\n","\treturn token_len\n","\n","\n","def gen_token(file):\n","\ttokens = []\n","\n","\twith open(file, 'r', encoding=\"utf-8\") as f:\n","\t\tfor line in f:\n","\t\t\ttokens += (line.split(' '))\n","\n","\treturn tokens\n","\n","\n","def gen_vocabulary(file):\n","\tword_list = []\n","\twith open(file, 'r', encoding=\"utf-8\") as f:\n","\t\tfor line in f:\n","\t\t\tline=line.replace('\\n','')\n","\t\t\tword_list += (line.split(' '))\n","\n","\tword_counts = Counter(word_list)\n","\treturn word_counts"]},{"cell_type":"markdown","metadata":{"id":"Wm8zOCBM9dno"},"source":["Displaying Token Count and Vocabulary Count"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114964,"status":"ok","timestamp":1713693402451,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"OKF75UJ-9dno","outputId":"af48e4ec-5420-426c-b494-8a35b7c98cde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Corpus Tokens : 86699267\n","Number of Pre Processed Corpus Tokens : 38735251\n","Size of Vocabulary : 2108503\n"]}],"source":["corpus_token_count = gen_token_count(corpus_file)\n","print(\"Number of Corpus Tokens :\", corpus_token_count)\n","\n","preprocess_token_count = gen_token_count(preprocessed_file)\n","print(\"Number of Pre Processed Corpus Tokens :\", preprocess_token_count)\n","\n","vocab_counts = gen_vocabulary(preprocessed_file)\n","print(\"Size of Vocabulary :\", len(vocab_counts))"]},{"cell_type":"markdown","metadata":{"id":"7qwly_J89dno"},"source":["Reducing the vocabulary to words which occur more than 100 times since the total vocabulary count cannot be allocated as a 2D matrix"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1713693402452,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"9bW95qj69dno","outputId":"914c0bb1-c145-4552-8309-c2d9d330b42b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of reduced Vocabulary : 18706\n"]}],"source":["\n","vocab = {x for x, count in vocab_counts.items() if count >= 100}\n","print(\"Size of reduced Vocabulary :\", len(vocab))\n"]},{"cell_type":"markdown","metadata":{"id":"1P-0cLfq9dno"},"source":["Necessary variables for making the Co-Occurance matrix"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":869,"status":"ok","timestamp":1713693403312,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"IqHW-BmB9dno"},"outputs":[],"source":["vocab_list = list(vocab)\n","vocab_pos = {vocab_list[i]: i for i in range(len(vocab_list))}\n","vocab_idx = vocab_pos.copy()\n","vocab_idx.update({i: w for i, w in enumerate(vocab_list)})"]},{"cell_type":"markdown","metadata":{"id":"WnHTf4uA9dno"},"source":["Creating the Co-Occurance matrix"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":646551,"status":"ok","timestamp":1713694110453,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"nVOB-NxA9dno","outputId":"77e24872-0bcb-463a-e583-25d53b067618"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 38700000/38735257 [10:40<00:00, 60459.40it/s] "]},{"name":"stdout","output_type":"stream","text":["\n","Grams processed = 38735256\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def co_occurances(file):\n","\twindow = 5\n","\n","\t# Using a ramp of window 4\n","\tramp = [0] + [*range(window, 0, -1)]\n","\n","\toccurances = np.zeros((len(vocab), len(vocab)), dtype=np.int64)\n","\n","\tgram_count=0\n","\tline=''\n","\n","\twith open(file, 'r', encoding=\"utf-8\") as corpus:\n","\t\tfor corp in corpus:\n","\t\t\tline=corp\n","\n","\tpg_bar=tqdm(total=gramms_limit)\n","\n","\tall_grams = ngrams(word_tokenize(line), window+1,pad_right=True, pad_left=True)\n","\n","\tfor grams in all_grams:\n","\n","\t\tif grams[0] in vocab:\n","\t\t\tfor idx, gram in enumerate(grams):\n","\t\t\t\tif gram in vocab:\n","\t\t\t\t\toccurances[vocab_idx[grams[0]]][vocab_idx[gram]] += ramp[idx]\n","\n","\t\t# Doing the same as above with the gram reversed\n","\t\tgrams_rev = grams[::-1]\n","\n","\t\tif grams_rev[0] in vocab:\n","\t\t\tfor idx, gram in enumerate(grams_rev):\n","\t\t\t\tif gram in vocab:\n","\t\t\t\t\toccurances[vocab_idx[grams_rev[0]]][vocab_idx[gram]] += ramp[idx]\n","\n","\t\tgram_count+=1\n","\n","\t\tif gram_count % 100000 == 0:\n","\t\t\tpg_bar.update(100000)\n","\n","\tpg_bar.close()\n","\n","\tprint(f'\\nGrams processed = {gram_count}')\n","\n","\treturn occurances\n","\n","cocrmat = co_occurances(preprocessed_file)\n"]},{"cell_type":"markdown","metadata":{"id":"ciea0Wba9dno"},"source":["Calculating overall Pi and Pj values of the Co-Occurance matrix"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1416,"status":"ok","timestamp":1713694472069,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"3koiiFdA9dnp"},"outputs":[],"source":["\n","def calculate_probability(co_occurrence_matrix):\n","\t# Calculate row sums and column sums\n","\trow_sums = np.sum(co_occurrence_matrix, axis=1)\n","\tcol_sums = np.sum(co_occurrence_matrix, axis=0)\n","\n","\t# Total co-occurrences\n","\tN = np.sum(co_occurrence_matrix)\n","\n","\tif(N==0):\n","\t\treturn 0,0\n","\n","\t# Calculate pi and pj\n","\tpi = row_sums / N\n","\tpj = col_sums / N\n","\n","\treturn pi, pj\n","\n","\n","# Calculate pi and pj\n","pi, pj = calculate_probability(cocrmat)"]},{"cell_type":"markdown","metadata":{"id":"Ho_1FDUO9dnp"},"source":["Generating the Positive Pointwise Mutual Information (PPMI) matrix from the Co-Occurance matrix"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391568,"status":"ok","timestamp":1713694865502,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"qmd_FdWZ9dnp","outputId":"87657847-44e4-4317-f7c2-6278c2df8161"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18706/18706 [06:30<00:00, 47.84it/s]\n"]}],"source":["\n","def gen_ppmi_matrix(co_occurrence_matrix):\n","\tppmi_matrix = np.zeros((len(vocab), len(vocab)))\n","\n","\trow_sums = np.sum(co_occurrence_matrix, axis=1)\n","\tfor i in tqdm(range(len(vocab))):\n","\t\tfor j in range(len(vocab)):\n","\n","\t\t\tif (row_sums[i] == 0 or co_occurrence_matrix[i][j] == 0):\n","\t\t\t\tppmi_matrix[i][j] = 0\n","\t\t\t\tcontinue\n","\t\t\tpij = ((co_occurrence_matrix[i][j]))/row_sums[i]\n","\t\t\tppmi_matrix[i][j] = max(0, math.log2(pij/(pi[i]*pj[j])))\n","\n","\treturn ppmi_matrix\n","\n","\n","ppmi_matrix = gen_ppmi_matrix(cocrmat)"]},{"cell_type":"markdown","metadata":{"id":"lPF4jZ9O9dnp"},"source":["Functions for calculating similar words"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1713694865503,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"MfH2wvVl9dnq"},"outputs":[],"source":["def calc_norm(vec):\n","\tsum_of_squares = sum(x**2 for x in vec)\n","\treturn math.sqrt(sum_of_squares)\n","\n","\n","def cosine_similarity(vec1, vec2):\n","\tv1 = list(vec1)\n","\tv2 = list(vec2)\n","\n","\tdot_product = (0.0)\n","\n","\tfor i in range(len(v1)):\n","\t\ttemp = dot_product\n","\t\tdot_product += (v1[i]*v2[i])\n","\t# print(dot_product)\n","\tnorm_vec1 = calc_norm(v1)\n","\tnorm_vec2 = calc_norm(v2)\n","\treturn dot_product / (norm_vec1 * norm_vec2)\n","\n","\n","def reshape_top(words, extra):\n","\tlow = 0\n","\thigh = len(words) - 1\n","\n","\twhile low <= high:\n","\t\tmid = (low + high) // 2\n","\t\tif words[mid][1] < extra[1]:\n","\t\t\tlow = mid + 1\n","\t\telif words[mid][1] > extra[1]:\n","\t\t\thigh = mid - 1\n","\t\telse:\n","\t\t\tbreak\n","\n","\twords.insert(low, extra)\n","\treturn words[1:]\n","\n","\n","def find_similar_words(target_word, vocab, ppmi_matrix, top_n=10):\n","\ttop_n += 1\n","\tif target_word not in vocab:\n","\t\tprint(\"Target word not found in the vocabulary.\")\n","\t\treturn\n","\n","\ttarget_index = vocab_pos[target_word]\n","\ttarget_vector = ppmi_matrix[target_index]\n","\n","\tsimilarities = [(vocab_idx[0], 0.0) for _ in range(top_n)]\n","\n","\tfor i, vector in enumerate(ppmi_matrix):\n","\t\tsim = cosine_similarity(target_vector, vector)\n","\t\tsimilarities = reshape_top(similarities, (vocab_idx[i], sim))\n","\n","\tsimilarities.reverse()\n","\n","\treturn similarities[1:]"]},{"cell_type":"markdown","metadata":{"id":"lX1pssku9dnq"},"source":["Generating the Top 15 words and choosing the Top 10 nouns from them"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1713694993606,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"T0zW0Tt69dnq","outputId":"5b630b66-50f5-4b20-934a-7c8abefff6c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 15 popular words :  ['रूप', 'हिप्पोकैम्पस', 'उपहार', 'नहीं', 'राज्य', 'ओडिन', 'बच्चों', 'भारत', 'ओलंपिक', 'स्मृति', 'नाम', 'ईसाई', 'विशेष', 'प्रकार', 'क्रिसमस']\n","Top 10 popular nouns :  ['रूप', 'हिप्पोकैम्पस', 'उपहार', 'राज्य', 'ओडिन', 'बच्चों', 'भारत', 'ओलंपिक', 'स्मृति', 'ईसाई']\n"]}],"source":["top_15 = vocab_counts.most_common(15)\n","top_15 = [i for i, _ in top_15]\n","print(\"Top 15 popular words : \", top_15)\n","\n","nouns = [top_15[0], top_15[1], top_15[2], top_15[4], top_15[5],\n","\t\ttop_15[6], top_15[7], top_15[8], top_15[9], top_15[11]]\n","print(\"Top 10 popular nouns : \", nouns)"]},{"cell_type":"markdown","metadata":{"id":"Imp4ooDa9dnq"},"source":["Displaying similar words for the nouns"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3039388,"status":"ok","timestamp":1713698033725,"user":{"displayName":"Anurag Gupta","userId":"09995351267288917742"},"user_tz":-330},"id":"aMhNqDNs9dnq","outputId":"b70d4005-f4f0-45e7-82fe-68252a476844"},"outputs":[{"name":"stdout","output_type":"stream","text":["Words similar to 'रूप':\n","\tनहीं: 0.9487072218611369\n","\tउन्होंने: 0.9300621013389434\n","\tसबसे: 0.9295931282106752\n","\tनाम: 0.9277516621623187\n","\tकारण: 0.9259441237081238\n","\tशामिल: 0.9186821937048171\n","\tकाम: 0.9028323314003894\n","\tप्राप्त: 0.9000391196345271\n","\tमुख्य: 0.8995005017423251\n","\tप्रमुख: 0.8914432497554523\n","Words similar to 'हिप्पोकैम्पस':\n","\tविभेदस्थानिक: 0.720721328652459\n","\tभूमिकाहिप्पोकैम्पस: 0.716292772874085\n","\tदिशानिर्देशन: 0.6929263481764727\n","\tभूमिकाा: 0.6427220666189853\n","\tभूमिकाे: 0.6323230290634059\n","\tभूमिकां: 0.6242357862046938\n","\tभूमिकाी: 0.5855576984290631\n","\tस्मृति: 0.3232409766622341\n","\tमेडियल: 0.32040773148090795\n","\tभूमिकारूप: 0.3168999478220527\n","Words similar to 'उपहार':\n","\tउत्पत्तिउपहार: 0.5085022245806071\n","\tसिंटरक्लास: 0.3055436794275977\n","\tउत्पत्तिर: 0.3023470627281467\n","\tमिलतेआधुनिक: 0.28301821826856133\n","\tदिन: 0.26910517450294785\n","\tदेने: 0.2681297706206066\n","\tक्रिसमस: 0.26735380380633333\n","\tघर: 0.26472965886513794\n","\tबच्चों: 0.2641047079927667\n","\tलोगों: 0.26390195090873453\n","Words similar to 'राज्य':\n","\tभारत: 0.872930592501204\n","\tक्षेत्र: 0.8465035109263611\n","\tनाम: 0.8342443086489209\n","\tसबसे: 0.8308133032091879\n","\tभारतीय: 0.829556481703617\n","\tउन्होंने: 0.8293562248007961\n","\tरूप: 0.821623397329681\n","\tप्रमुख: 0.8207424900814382\n","\tपूर्व: 0.8185902175978276\n","\tकारण: 0.8144561622058518\n","Words similar to 'ओडिन':\n","\tउत्पत्तिओडिन: 0.6522855784465456\n","\tस्लीप्निर: 0.42582073962275546\n","\tउत्पत्तिे: 0.4155384798637631\n","\tमिलतेआधुनिक: 0.39874814845521134\n","\tउत्पत्तिं: 0.3716888866535467\n","\tउत्पत्तिी: 0.36189488200441017\n","\tउत्पत्तिा: 0.3555425717418439\n","\tक्लॉज़: 0.3448064936385816\n","\tस्केल्डिक: 0.3443368755986485\n","\tबैगसेंट: 0.33543798591113383\n","Words similar to 'बच्चों':\n","\tलोगों: 0.664325333704646\n","\tनहीं: 0.6636912409000121\n","\tकाम: 0.6556784510774951\n","\tउन्होंने: 0.6504677817954049\n","\tजीवन: 0.6502234481210775\n","\tक्योंकि: 0.6488358343295322\n","\tकारण: 0.6478127849716583\n","\tव्यक्ति: 0.6467004501301568\n","\tरूप: 0.6445466692039037\n","\tबच्चे: 0.6406502932930365\n","Words similar to 'भारत':\n","\tभारतीय: 0.9053601379936701\n","\tनाम: 0.8895812019251451\n","\tउन्होंने: 0.8862834568467457\n","\tसबसे: 0.8857861580421876\n","\tरूप: 0.8796752821498093\n","\tक्षेत्र: 0.8772403430953746\n","\tराज्य: 0.872930592501204\n","\tनहीं: 0.8728860126522067\n","\tप्रमुख: 0.8674636127054429\n","\tकारण: 0.8654279984495853\n","Words similar to 'ओलंपिक':\n","\tग्रीष्मकालीन: 0.600366025615254\n","\tखेलों: 0.578703605012917\n","\tपदक: 0.5030674994694871\n","\tशीतकालीन: 0.49290218771317457\n","\tचैंपियनशिप: 0.46275898769664414\n","\tटूर्नामेंट: 0.45644585594674775\n","\tटीम: 0.445487397977815\n","\tएथलीटों: 0.4411999095593925\n","\tशहरइतिहासप्रारंभिक: 0.4404667075854617\n","\tकप: 0.43881617984558763\n","Words similar to 'स्मृति':\n","\tरूप: 0.4702648229504572\n","\tजी: 0.46938705876272624\n","\tकार्य: 0.46535209256639276\n","\tजीवन: 0.4625475529793192\n","\tनहीं: 0.46217090340980416\n","\tव्यक्ति: 0.4616609812164788\n","\tअनेक: 0.4605498736858477\n","\tकरती: 0.46045396869057414\n","\tसाहित्य: 0.4598559007481292\n","\tकारण: 0.45816674841870175\n","Words similar to 'ईसाई':\n","\tधर्म: 0.587190006853805\n","\tधार्मिक: 0.541910166049275\n","\tलोगों: 0.5295292818111643\n","\tइस्लाम: 0.5289899662404427\n","\tचर्च: 0.5256747559229754\n","\tमुस्लिम: 0.521540085608601\n","\tकैथोलिक: 0.5093026061994134\n","\tसमुदाय: 0.5059290630721026\n","\tजीवन: 0.5030946902124815\n","\tसमाज: 0.503025956352905\n"]}],"source":["for noun in nouns:\n","\ttarget_word = noun\n","\tsimilar_words = find_similar_words(target_word, vocab, ppmi_matrix)\n","\n","\tprint(f\"Words similar to '{target_word}':\")\n","\tfor word, similarity in similar_words:\n","\t\tprint(f\"\t{word}: {similarity}\")"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
